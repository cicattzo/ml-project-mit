{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP \n",
    "using Gurobi \n",
    "using CSV \n",
    "using LinearAlgebra\n",
    "using DataFrames\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gurobi.Env(Ptr{Nothing} @0x00007fa4a01c0e00)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gurobi_env = Gurobi.Env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_inds::Union{AbstractVector, Regex, Not})` is deprecated, use `df[:, col_inds]` instead.\n",
      "│   caller = top-level scope at In[170]:2\n",
      "└ @ Core In[170]:2\n",
      "┌ Warning: `getindex(df::DataFrame, col_inds::Union{AbstractVector, Regex, Not})` is deprecated, use `df[:, col_inds]` instead.\n",
      "│   caller = top-level scope at In[170]:5\n",
      "└ @ Core In[170]:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3658×14 Array{Float64,2}:\n",
       " 1.0  39.0  0.0   0.0  0.0  0.0  0.0  …  106.0   70.0  26.97  80.0   77.0\n",
       " 0.0  46.0  0.0   0.0  0.0  0.0  0.0     121.0   81.0  28.73  95.0   76.0\n",
       " 1.0  48.0  1.0  20.0  0.0  0.0  0.0     127.5   80.0  25.34  75.0   70.0\n",
       " 0.0  61.0  1.0  30.0  0.0  0.0  1.0     150.0   95.0  28.58  65.0  103.0\n",
       " 0.0  46.0  1.0  23.0  0.0  0.0  0.0     130.0   84.0  23.1   85.0   85.0\n",
       " 0.0  43.0  0.0   0.0  0.0  0.0  1.0  …  180.0  110.0  30.3   77.0   99.0\n",
       " 0.0  63.0  0.0   0.0  0.0  0.0  0.0     138.0   71.0  33.11  60.0   85.0\n",
       " 0.0  45.0  1.0  20.0  0.0  0.0  0.0     100.0   71.0  21.68  79.0   78.0\n",
       " 1.0  52.0  0.0   0.0  0.0  0.0  1.0     141.5   89.0  26.36  76.0   79.0\n",
       " 1.0  43.0  1.0  30.0  0.0  0.0  1.0     162.0  107.0  23.61  93.0   88.0\n",
       " 0.0  50.0  0.0   0.0  0.0  0.0  0.0  …  133.0   76.0  22.91  75.0   76.0\n",
       " 0.0  43.0  0.0   0.0  0.0  0.0  0.0     131.0   88.0  27.64  72.0   61.0\n",
       " 1.0  46.0  1.0  15.0  0.0  0.0  1.0     142.0   94.0  26.31  98.0   64.0\n",
       " ⋮                          ⋮         ⋱           ⋮                      \n",
       " 1.0  47.0  1.0   3.0  0.0  0.0  0.0     120.0   80.0  25.23  75.0   76.0\n",
       " 1.0  45.0  1.0  43.0  0.0  0.0  0.0     137.5   85.0  24.24  83.0  105.0\n",
       " 1.0  58.0  0.0   0.0  0.0  0.0  0.0     125.5   84.0  26.05  67.0   76.0\n",
       " 1.0  43.0  1.0  20.0  0.0  0.0  0.0     129.5   88.0  25.62  80.0   75.0\n",
       " 0.0  50.0  0.0   0.0  0.0  0.0  1.0  …  190.0  130.0  43.67  85.0  260.0\n",
       " 1.0  58.0  0.0   0.0  0.0  0.0  1.0     141.0   81.0  24.96  80.0   81.0\n",
       " 1.0  68.0  0.0   0.0  0.0  0.0  1.0     168.0   97.0  23.14  60.0   79.0\n",
       " 1.0  50.0  1.0   1.0  0.0  0.0  1.0     179.0   92.0  25.97  66.0   86.0\n",
       " 1.0  51.0  1.0  43.0  0.0  0.0  0.0     126.5   80.0  19.71  65.0   68.0\n",
       " 0.0  52.0  0.0   0.0  0.0  0.0  0.0  …  133.5   83.0  21.47  80.0  107.0\n",
       " 1.0  40.0  0.0   0.0  0.0  0.0  1.0     141.0   98.0  25.6   67.0   72.0\n",
       " 0.0  39.0  1.0  30.0  0.0  0.0  0.0     133.0   86.0  20.91  85.0   80.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = CSV.read(\"framingham.csv\")\n",
    "df = df[setdiff(names(df), [:education])]\n",
    "\n",
    "y = df.TenYearCHD\n",
    "X = Matrix(df[setdiff(names(df), [:TenYearCHD])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3101-element view(::Array{Int64,1}, [1, 2, 3, 5, 6, 8, 9, 10, 11, 12  …  3645, 3647, 3648, 3650, 3651, 3652, 3655, 3656, 3657, 3658]) with eltype Int64:\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       "  ⋮\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y.<1].=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainvalid_test_split (generic function with 2 methods)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function trainvalid_test_split(X, y, split_at=0.7)\n",
    "    n,p = size(X)\n",
    "    split = convert(Int,floor(split_at*n))\n",
    "    permuted_indices = randperm(n)\n",
    "    trainvalid_indices, test_indices = permuted_indices[1:split], permuted_indices[split+1:end]\n",
    "    X_trainvalid, y_trainvalid = X[trainvalid_indices,:], y[trainvalid_indices]\n",
    "    X_test, y_test = X[test_indices,:], y[test_indices]\n",
    "    return X_trainvalid, X_test, y_trainvalid, y_test\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rlr (generic function with 1 method)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Utils Functions ###\n",
    "function compute_∇f(w_k, y, X, λ)\n",
    "    n, p = size(X)\n",
    "    temp = zeros(p)\n",
    "    for i in 1:n\n",
    "        t = min(exp(-y[i]*(transpose(w_k)*Array(X[i,:]))+λ*transpose(w_k)*w_k),1000000)\n",
    "#         t = exp(-y[i]*(transpose(w_k)*Array(X[i,:]))+λ*transpose(w_k)*w_k)\n",
    "        Δ = (1/(1+t))*t*(-y[i]*Array(X[i,:]) .+ 2*λ*w_k)\n",
    "        temp = temp + Δ\n",
    "    end\n",
    "    ∇f_k = temp\n",
    "    return ∇f_k\n",
    "end\n",
    "\n",
    "function rlr(y, X, ε, λ)\n",
    "    errors = []\n",
    "    n, p = size(X)\n",
    "    w_0 = [0 for i in 1:p]\n",
    "    f_0 = sum(log(1+exp(-y[i]*dot(X[i,:], w_0)+λ*transpose(w_0)*w_0)) for i=1:n)\n",
    "    ∇f_0 = compute_∇f(w_0, y, X, λ)\n",
    "\n",
    "    # Outer minimization problem\n",
    "    outer_min_model = Model(solver=GurobiSolver(OutputFlag=0, gurobi_env))\n",
    "    @variable(outer_min_model, t >= 0)\n",
    "    @variable(outer_min_model, w[1:p])\n",
    "    #@constraint(outer_min_model, [j=1:p], -1 <= w[j] <= 1)\n",
    "    @constraint(outer_min_model, t >= f_0 + (dot(∇f_0, w)-dot(∇f_0, w_0)))\n",
    "    @constraint(outer_min_model, [j=1:p], 10 >= w[j])\n",
    "    @constraint(outer_min_model, [j=1:p], w[j] >= -10)\n",
    "    @objective(outer_min_model, Min, t)\n",
    "    k = 1 # Number of constraints in the final problem\n",
    "    solve(outer_min_model)\n",
    "\n",
    "    # New steps k\n",
    "    t_k = getvalue(t)\n",
    "    w_k = getvalue(w)  \n",
    "    f_k = sum(min(log(1+exp(-y[i]*dot(X[i,:], w_k)+λ*transpose(w_k)*w_k)),100) for i=1:n)\n",
    "    ∇f_k = compute_∇f(w_k, y, X, λ)\n",
    "    \n",
    "    while abs(f_k - t_k) >= ε # error\n",
    "\n",
    "        push!(errors, f_k - t_k)\n",
    "        @constraint(outer_min_model,t >= f_k +(dot(∇f_k, w)-dot(∇f_k, w_k)))\n",
    "        k += 1\n",
    "        solve(outer_min_model)\n",
    "        # Updating all the values\n",
    "        t_k = getvalue(t)\n",
    "        w_k = getvalue(w)\n",
    "        f_k = sum(min(log(1+exp(-y[i]*dot(X[i,:], w_k)+λ*transpose(w_k)*w_k)),10000) for i=1:n)\n",
    "\n",
    "        ∇f_k = compute_∇f(w_k, y, X, λ)\n",
    "         if k%100 == 0\n",
    "             println(\"Number of constraints: \", k, \"\\t Error = \", abs(t_k - f_k))\n",
    "#             println(\"f\",f_k)\n",
    "#             println(\"t\",t_k)\n",
    "#             println(\"∇f_k\",∇f_k)\n",
    "         end\n",
    "        if k > 20000\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    push!(errors, f_k - t_k)\n",
    "    return t_k, f_k, w_k, errors\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Robust Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "srlr (generic function with 1 method)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function classification_metrics(preds, actual)\n",
    "    accuracy = sum(preds .== actual)/size(preds)[1]\n",
    "    tpr = dot(\n",
    "        (preds.==1),actual.==1\n",
    "        )/(\n",
    "        dot((preds.==1),actual.==1\n",
    "            ) + dot(\n",
    "            (preds.==-1),actual.==1)\n",
    "    )\n",
    "    fpr = dot(\n",
    "        (preds.==1),actual.==-1\n",
    "        )/ (\n",
    "        dot((preds.==1),actual.==-1\n",
    "            ) + dot(\n",
    "            (preds.==-1),actual.==-1)\n",
    "    )\n",
    "    return accuracy, tpr, fpr\n",
    "end\n",
    "\n",
    "function compute_derivative(w, z, y, X, alpha)\n",
    "    \n",
    "    n, p = size(X)\n",
    "    \n",
    "    derivative = sum(\n",
    "        (\n",
    "            z[i]*(2*alpha.*w-y[i].*X[i,:])*exp(-y[i]*dot(w,X[i,:])+alpha.*dot(w,w))\n",
    "            )/(\n",
    "            exp(-y[i]*dot(w,X[i,:])+alpha.*dot(w,w))+1\n",
    "            ) for i in 1:n\n",
    "        )\n",
    "    \n",
    "    return derivative\n",
    "    \n",
    "end\n",
    "\n",
    "function inner(w, y, X, k, alpha)\n",
    "    \n",
    "    n, p = size(X)\n",
    "    \n",
    "    model_inner = Model(solver=GurobiSolver(OutputFlag=0,gurobi_env))\n",
    "    \n",
    "    @variable(model_inner, z[1:n] >= 0)\n",
    "    \n",
    "    @constraint(model_inner, [i=1:n], 1 >= z[i])\n",
    "    @constraint(model_inner, sum(z) <= k)\n",
    "    \n",
    "    @objective(model_inner,\n",
    "        Max,\n",
    "        sum(z[i]*log(1+exp(-y[i]*dot(X[i,:], w)+ alpha*dot(w,w))) for i=1:n)\n",
    "    )\n",
    "    \n",
    "    solve(model_inner)\n",
    "    \n",
    "    optimal_z = getvalue(z)\n",
    "    optimal_f = getobjectivevalue(model_inner)\n",
    "    \n",
    "    return optimal_z, optimal_f\n",
    "    \n",
    "end\n",
    "\n",
    "function srlr(y, X, epsilon, k, alpha)\n",
    "    deltas = []\n",
    "    n, p = size(X)\n",
    "    initialization_w = [0 for i in 1:p]\n",
    "    initialization_z, initial_f = inner(initialization_w, y, X, k, alpha)\n",
    "    initial_derivative_f = compute_derivative(initialization_w, initialization_z, y, X, alpha)\n",
    "    \n",
    "    model_outer = Model(solver=GurobiSolver(OutputFlag=0, gurobi_env))\n",
    "    \n",
    "    @variable(model_outer, t >= 0)\n",
    "    @variable(model_outer, w[1:p])\n",
    "    \n",
    "    @constraint(\n",
    "        model_outer, t >= initial_f + dot(initial_derivative_f, w)-dot(initial_derivative_f, initialization_w)\n",
    "    )\n",
    "    @constraint(model_outer, [j=1:p], 10 >= w[j])\n",
    "    @constraint(model_outer, [j=1:p], w[j] >= -10)\n",
    "    \n",
    "    @objective(model_outer, Min, t)\n",
    "    \n",
    "    number_const = 1\n",
    "    solve(model_outer)\n",
    "\n",
    "    t_new = getvalue(t)\n",
    "    w_new = getvalue(w)\n",
    "    z_new, f_new = inner(w_new, y, X, k, alpha)\n",
    "\n",
    "    derivative_f_new = compute_derivative(w_new, z_new, y, X, alpha)\n",
    "    while abs(f_new - t_new) >= epsilon\n",
    "        \n",
    "        push!(deltas, f_new - t_new)\n",
    "        \n",
    "        @constraint(model_outer,t >= f_new + dot(derivative_f_new, w)-dot(derivative_f_new, w_new))\n",
    "        \n",
    "        number_const += 1\n",
    "        solve(model_outer)\n",
    "        t_new = getvalue(t)\n",
    "        w_new = getvalue(w)\n",
    "        z_new, f_new = inner(w_new, y, X, k, alpha)\n",
    "\n",
    "        derivative_f_new = compute_derivative(w_new, z_new, y, X, alpha)\n",
    "        \n",
    "        if number_const%100 == 0\n",
    "            println(\"Number of constraints: \", number_const, \"\\t Step delta = \", abs(t_new - f_new))\n",
    "        end\n",
    "        \n",
    "        if number_const > 100000\n",
    "            break\n",
    "            \n",
    "        end\n",
    "    end\n",
    "    push!(deltas, f_new - t_new)\n",
    "    return t_new, f_new, w_new, z_new, deltas\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation of SRLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification_metrics (generic function with 1 method)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function classification_metrics(preds, actual)\n",
    "    accuracy = sum(preds .== actual)/size(preds)[1]\n",
    "    tpr = dot(\n",
    "        (preds.==1),actual.==1\n",
    "        )/(\n",
    "        dot((preds.==1),actual.==1\n",
    "            ) + dot(\n",
    "            (preds.==-1),actual.==1)\n",
    "    )\n",
    "    fpr = dot(\n",
    "        (preds.==1),actual.==-1\n",
    "        )/ (\n",
    "        dot((preds.==1),actual.==-1\n",
    "            ) + dot(\n",
    "            (preds.==-1),actual.==-1)\n",
    "    )\n",
    "    return accuracy, tpr, fpr\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validation_srlr (generic function with 3 methods)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function validation_srlr(X_trainvalid, y_trainvalid, alpha_values, epsilon = 0.001, persent_traindata = 0.8)\n",
    "    for alpha in alpha_values\n",
    "        (t_opt, f_opt, w_opt, z_opt, deltas) = srlr(y_trainvalid, X_trainvalid, epsilon, floor(Int, persent_traindata*size(X)[1]), alpha)\n",
    "        \n",
    "        train_index = z_opt.>0\n",
    "        validation_index = z_opt.==0\n",
    "        \n",
    "        X_train = X_trainvalid[train_index,:]\n",
    "        X_val = X_trainvalid[validation_index,:]\n",
    "        y_train = y_trainvalid[train_index,:]\n",
    "        y_val = y_trainvalid[validation_index,:]\n",
    "        \n",
    "        \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of constraints: 100\t Step delta = 450.611077280118\n",
      "Number of constraints: 200\t Step delta = 34.42976491763079\n",
      "Number of constraints: 300\t Step delta = 12.731731705738866\n",
      "Number of constraints: 400\t Step delta = 1.793293794982901\n",
      "Number of constraints: 500\t Step delta = 0.8262476568622787\n",
      "Number of constraints: 600\t Step delta = 0.42397979336601566\n",
      "Number of constraints: 700\t Step delta = 0.4087229006754569\n",
      "Number of constraints: 800\t Step delta = 0.49288165758230207\n",
      "Number of constraints: 900\t Step delta = 0.07979186324337206\n",
      "Number of constraints: 1000\t Step delta = 0.009430091224885473\n",
      "Number of constraints: 1100\t Step delta = 0.009365729097908115\n",
      "Number of constraints: 1200\t Step delta = 0.004592697619273167\n",
      "Number of constraints: 1300\t Step delta = 0.0011569238658921677\n",
      "Number of constraints: 1400\t Step delta = 0.0005311643324148463\n",
      "Number of constraints: 1500\t Step delta = 0.00016919335303100524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1774.4567317380743, 1774.4568251702344, [5.84426e-5, -0.000106432, -0.000123686, 0.000253578, 0.000202987, 0.000224945, -9.48432e-5, 0.000152416, 6.83622e-5, -2.63029e-5, 0.000127889, 0.000280977, -0.000119299, -4.65849e-5], [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0  …  0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0], Any[4148.27, 4109.31, 3757.92, 3630.09, 3670.98, 4019.53, 3475.53, 10564.8, 4785.48, 3443.78  …  0.000779462, 0.000295679, 0.000198557, 0.000113739, 0.000691227, 0.000264811, 0.000112764, 0.000178878, 0.000145767, 9.34322e-5])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t_opt, f_opt, w_opt, z_opt, deltas) = srlr(y, X, 0.0001, floor(Int, 0.7*size(X)[1]), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "BoundsError",
     "evalue": "BoundsError: attempt to access 2926×14 Array{Float64,2} at index [Base.LogicalIndex(Bool[true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true]), Base.Slice(Base.OneTo(14))]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 2926×14 Array{Float64,2} at index [Base.LogicalIndex(Bool[true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true]), Base.Slice(Base.OneTo(14))]",
      "",
      "Stacktrace:",
      " [1] throw_boundserror(::Array{Float64,2}, ::Tuple{Base.LogicalIndex{Int64,BitArray{1}},Base.Slice{Base.OneTo{Int64}}}) at ./abstractarray.jl:484",
      " [2] checkbounds at ./abstractarray.jl:449 [inlined]",
      " [3] _getindex at ./multidimensional.jl:596 [inlined]",
      " [4] getindex(::Array{Float64,2}, ::BitArray{1}, ::Function) at ./abstractarray.jl:905",
      " [5] top-level scope at In[155]:3"
     ]
    }
   ],
   "source": [
    "train_index = z_opt.>0\n",
    "validation_index = z_opt.==0\n",
    "\n",
    "X_train = X_trainvalid[train_index,:]\n",
    "X_val = X_trainvalid[validation_index,:]\n",
    "y_train = y_trainvalid[train_index,:]\n",
    "y_val = y_trainvalid[validation_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of constraints: 100\t Error = 16464.238273702544\n",
      "Number of constraints: 200\t Error = 32287.794876331292\n",
      "Number of constraints: 300\t Error = 4364.517851371021\n",
      "Number of constraints: 400\t Error = 932.8089195938776\n",
      "Number of constraints: 500\t Error = 374.84910259835215\n",
      "Number of constraints: 600\t Error = 17.937704633541216\n",
      "Number of constraints: 700\t Error = 1.9139566112585271\n",
      "Number of constraints: 800\t Error = 0.06895640810398618\n",
      "Number of constraints: 900\t Error = 0.002712767700813856\n",
      "Number of constraints: 1000\t Error = 7.566360454802634e-5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2149.643689369181, 2149.6436984113043, [6.72665e-5, 0.00592276, 4.55819e-5, 0.00128986, 6.63366e-5, 1.09402e-5, 7.74492e-6, -2.84327e-5, 0.0230511, 0.0146731, 0.00899947, 0.00288296, 0.00857109, 0.00889568], Any[310100.0, 403130.0, 3.91501e5, 3.59522e5, 3.41737e5, 316657.0, 3.45577e5, 2.84601e5, 276239.0, 2.36074e5  …  1.44288e-5, 1.25158e-5, 1.42291e-5, 1.45662e-5, 1.21705e-5, 1.28536e-5, 1.50384e-5, 1.6027e-5, 1.05034e-5, 9.04212e-6])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlr(y, X, 0.00001, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3658-element Array{Float64,1}:\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " ⋮  \n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0 35.0 … 75.0 88.0; 0.0 63.0 … 68.0 95.0; … ; 1.0 53.0 … 112.0 113.0; 1.0 53.0 … 76.0 108.0], [1.0 41.0 … 75.0 64.0; 0.0 59.0 … 58.0 88.0; … ; 1.0 43.0 … 64.0 90.0; 1.0 67.0 … 65.0 78.0], [-1, 1, -1, -1, 1, -1, -1, -1, -1, -1  …  -1, 1, -1, -1, -1, -1, 1, -1, -1, 1], [-1, -1, -1, -1, -1, -1, 1, -1, -1, -1  …  -1, -1, -1, -1, -1, -1, -1, -1, -1, 1])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainvalid, X_test, y_trainvalid, y_test = trainvalid_test_split(X, y, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of constraints: 100\t Step delta = 0.14441777389970412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1148.6599618827693, 1148.6600589144552, [0.1, 0.0121299, -0.1, 0.0103748, 0.1, 0.1, 0.1, 0.1, -0.00208591, 0.0186503, -0.0258066, -0.0376939, -0.0173598, 0.00233043], [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], Any[33138.0, 2796.93, 2062.35, 2797.09, 1754.2, 1122.56, 1025.03, 1098.77, 895.766, 755.509  …  0.000307509, 0.000224657, 0.000167106, 0.00033757, 0.000143759, 0.000255214, 0.000152124, 0.000132474, 0.000155929, 9.70317e-5])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t_opt, f_opt, w_opt, z_opt, deltas) = srlr(y_trainvalid, X_trainvalid, 0.0001, floor(Int, 0.8*size(X_trainvalid)[1]), 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "586×1 Array{Int64,2}:\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       "  ⋮\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index = z_opt.>0\n",
    "validation_index = z_opt.==0\n",
    "\n",
    "X_train = X_trainvalid[train_index,:]\n",
    "X_val = X_trainvalid[validation_index,:]\n",
    "y_train = y_trainvalid[train_index,:]\n",
    "y_val = y_trainvalid[validation_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-586"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2024"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_trainvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stable_LR_cutting_planes (generic function with 1 method)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_∇f(w_k, z_k, y, X, λ)\n",
    "    n, p = size(X)\n",
    "    ∇f_k = sum(-z_k[i]/(1+exp(y[i]*dot(w_k,X[i,:])))*y[i].*X[i,:] for i in 1:n) + 2*λ.*w_k\n",
    "    return ∇f_k\n",
    "end\n",
    "\n",
    "function solve_inner_max_problem(w_k, y, X, K, λ)\n",
    "    n, p = size(X)\n",
    "    model_inner_max = Model(solver=GurobiSolver(OutputFlag=0,gurobi_env))\n",
    "    @variable(model_inner_max, z[1:n] >= 0)\n",
    "    @constraint(model_inner_max, [i=1:n], 1 >= z[i])\n",
    "    @constraint(model_inner_max, sum(z) <= K)\n",
    "    @objective(\n",
    "        model_inner_max,\n",
    "        Max,\n",
    "        sum(z[i]*log(1+exp(-y[i]*dot(X[i,:], w_k))) for i=1:n)\n",
    "    )\n",
    "    solve(model_inner_max)\n",
    "    optimal_z_k = getvalue(z)\n",
    "    optimal_f_k = getobjectivevalue(model_inner_max) + λ*dot(w_k,w_k)\n",
    "    return optimal_z_k, optimal_f_k\n",
    "end\n",
    "\n",
    "function scores(preds, gt)\n",
    "    acc = sum(preds .== gt)/size(preds)[1]\n",
    "    TPR = dot((preds.==1),gt.==1)/(dot((preds.==1),gt.==1) + dot((preds.==-1),gt.==1))\n",
    "    FPR = dot((preds.==1),gt.==-1)/ (dot((preds.==1),gt.==-1) + dot((preds.==-1),gt.==-1))\n",
    "    return acc, TPR, FPR\n",
    "end\n",
    "\n",
    "### Cutting Planes Implementation ###\n",
    "function stable_LR_cutting_planes(y, X, ε, K,λ)\n",
    "    errors = []\n",
    "    n, p = size(X)\n",
    "    # Initialization values and step 0\n",
    "    w_0 = [0 for i in 1:p]\n",
    "    #w_0 = [rand(Uniform(-0.5, 0.5)) for i in 1:p]\n",
    "    z_0, f_0 = solve_inner_max_problem(w_0, y, X, K, λ)\n",
    "    ∇f_0 = compute_∇f(w_0, z_0, y, X, λ)\n",
    "\n",
    "    # Outer minimization problem\n",
    "    outer_min_model = Model(solver=GurobiSolver(OutputFlag=0, gurobi_env))\n",
    "    @variable(outer_min_model, t >= 0)\n",
    "    @variable(outer_min_model, w[1:p])\n",
    "    #@constraint(outer_min_model, [j=1:p], -1 <= w[j] <= 1)\n",
    "    @constraint(outer_min_model, t >= f_0 + dot(∇f_0, w)-dot(∇f_0, w_0))\n",
    "    @constraint(outer_min_model, [j=1:p], 0.1 >= w[j])\n",
    "    @constraint(outer_min_model, [j=1:p], w[j] >= -0.1)\n",
    "    @objective(outer_min_model, Min, t)\n",
    "    k = 1 # Number of constraints in the final problem\n",
    "    solve(outer_min_model)\n",
    "\n",
    "    # New steps k\n",
    "    t_k = getvalue(t)\n",
    "    w_k = getvalue(w)\n",
    "    z_k, f_k = solve_inner_max_problem(w_k, y, X, K, λ)\n",
    "\n",
    "    ∇f_k = compute_∇f(w_k, z_k, y, X, λ)\n",
    "    while abs(f_k - t_k) >= ε # error\n",
    "        push!(errors, f_k - t_k)\n",
    "        @constraint(outer_min_model,t >= f_k + dot(∇f_k, w)-dot(∇f_k, w_k))\n",
    "        k += 1\n",
    "        solve(outer_min_model)\n",
    "        # Updating all the values\n",
    "        t_k = getvalue(t)\n",
    "        print(t_k)\n",
    "        print(\"\\n\")\n",
    "        w_k = getvalue(w)\n",
    "        z_k, f_k = solve_inner_max_problem(w_k, y, X, K, λ)\n",
    "\n",
    "        ∇f_k = compute_∇f(w_k, z_k, y, X, λ)\n",
    "        if k%100 == 0\n",
    "            println(\"Number of constraints: \", k, \"\\t Error = \", abs(t_k - f_k))\n",
    "        end\n",
    "        if k > 20000\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    push!(errors, f_k - t_k)\n",
    "    return t_k, f_k, w_k, z_k, errors\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "319.18432278103467\n",
      "439.80149192693585\n",
      "491.24645217327316\n",
      "496.61806600481435\n",
      "511.5292570878663\n",
      "533.3580918453265\n",
      "585.4559255940593\n",
      "623.9692366970115\n",
      "657.3295545250897\n",
      "684.2197805322998\n",
      "712.9274320737553\n",
      "760.214225194249\n",
      "846.8284979382622\n",
      "872.8989776379389\n",
      "886.2979400244232\n",
      "895.4862033501323\n",
      "931.3711639017648\n",
      "981.7544474565683\n",
      "986.950268910253\n",
      "1014.0669194872156\n",
      "1024.9814127763977\n",
      "1037.2569585044066\n",
      "1064.1544143160017\n",
      "1085.098390290637\n",
      "1090.4602643354533\n",
      "1092.3014117298221\n",
      "1095.302013371834\n",
      "1098.3108485043367\n",
      "1106.6085881927052\n",
      "1114.6494359066464\n",
      "1125.2374271904466\n",
      "1131.5282126069596\n",
      "1132.6028515080397\n",
      "1135.8791850762536\n",
      "1145.537062671298\n",
      "1146.1912912648197\n",
      "1146.6803752008002\n",
      "1149.9618613342043\n",
      "1154.884079395701\n",
      "1161.1935070253733\n",
      "1161.2784130391312\n",
      "1165.445426288458\n",
      "1165.9028331452741\n",
      "1166.0455458589418\n",
      "1166.1629845332832\n",
      "1170.7068407119152\n",
      "1171.1607154399865\n",
      "1172.5841502700446\n",
      "1173.4729298679722\n",
      "1174.3415635151764\n",
      "1175.0323633222984\n",
      "1176.1839822996603\n",
      "1177.6537688961455\n",
      "1178.0496660526087\n",
      "1178.7280279846925\n",
      "1179.166853248866\n",
      "1179.6373588358442\n",
      "1179.8744637936159\n",
      "1180.3704635505462\n",
      "1180.9516729021664\n",
      "1181.0616738763194\n",
      "1181.3831613011039\n",
      "1181.695038513115\n",
      "1181.9870393524207\n",
      "1182.0004195676331\n",
      "1182.0998989362274\n",
      "1182.2886659775388\n",
      "1182.4081857460583\n",
      "1182.438118440267\n",
      "1182.5902774881226\n",
      "1182.698258169833\n",
      "1182.7624277939592\n",
      "1182.8472985607243\n",
      "1182.858304573634\n",
      "1182.8716072947987\n",
      "1182.9693030804588\n",
      "1183.1244819115266\n",
      "1183.2734751759867\n",
      "1183.274745310337\n",
      "1183.312221079351\n",
      "1183.3416413713023\n",
      "1183.408458631857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1183.408458631857, 1184.1986037906315, [0.1, 0.0179555, -0.1, 0.0149135, 0.1, 0.1, 0.1, 0.1, -0.00305162, 0.0251707, -0.0325235, -0.0432265, -0.0239695, 0.00314173], [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], Any[33137.5, 2133.8, 2697.06, 3261.12, 1688.36, 1492.27, 1138.8, 1061.17, 1461.61, 803.694  …  1.83653, 2.8017, 2.13146, 1.29692, 1.14674, 1.37727, 1.67488, 1.00529, 1.25581, 0.790145])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t_opt, f_opt, w_opt, z_opt, deltas) = stable_LR_cutting_planes(y_trainvalid, X_trainvalid, 1.0, floor(Int, 0.9*size(X_trainvalid)[1]), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14-element Array{Float64,1}:\n",
       "  0.1                  \n",
       "  0.01795553849364385  \n",
       " -0.1                  \n",
       "  0.014913457869924275 \n",
       "  0.1                  \n",
       "  0.1                  \n",
       "  0.1                  \n",
       "  0.1                  \n",
       " -0.0030516186419622133\n",
       "  0.025170698237942202 \n",
       " -0.03252345585329899  \n",
       " -0.04322650210066299  \n",
       " -0.023969484443693987 \n",
       "  0.003141725281295585 "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183.408458631857"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293×1 Array{Int64,2}:\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       "  ⋮\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1\n",
       " -1"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index = z_opt.>0\n",
    "validation_index = z_opt.==0\n",
    "\n",
    "X_train = X_trainvalid[train_index,:]\n",
    "X_val = X_trainvalid[validation_index,:]\n",
    "y_train = y_trainvalid[train_index,:]\n",
    "y_val = y_trainvalid[validation_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-293"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1731"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2633"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
